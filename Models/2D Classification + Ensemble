from PIL import Image
import cv2
import matplotlib.pyplot as plt
#from keras.preprocessing.image import ImageDataGenerator
import glob
import os
import sys
import random
import numpy as np
from tqdm import tqdm
%matplotlib qt5
from shutil import copyfile
from skimage import morphology
from mpl_toolkits.axes_grid1 import make_axes_locatable
from skimage.morphology import label
from PIL import Image,ImageDraw,ImageFont
import pandas as pd 
from datetime import datetime
#from keras import utils as np_utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,CSVLogger
from tensorflow.keras.layers import Activation, Dense, Dropout
from tensorflow.keras.models import Model, load_model, save_model
import sklearn.metrics as metrics
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from tensorflow.keras.utils import normalize, to_categorical
from tensorflow.keras import backend as K 
np.random.seed(42)
from scipy import stats
from sklearn.preprocessing import LabelEncoder
from tensorflow.python.keras import regularizers

#plt.style.use("dark_background")


dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  
label = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.

# convert to numpay array.....
G1='B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G1/images_with_useful_info/masks/'
G2='B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G2/images_with_useful_info/masks/'
G3='B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G3/images_with _useful_info/masks/'


images = os.listdir(G1)
for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object
    if (image_name.split('.')[1] != 'db'):
        image = cv2.imread(G1+image_name)
        image = Image.fromarray(image, 'RGB')
        dataset.append(np.array(image))
        label.append(0)
        
images = os.listdir(G2)

for i, image_name in enumerate(images):    
    if (image_name.split('.')[1] != 'db'):
        image = cv2.imread(G2+image_name)
        image = Image.fromarray(image, 'RGB')
        dataset.append(np.array(image))
        label.append(1)
        
images = os.listdir(G3)

for i, image_name in enumerate(images):    
    if (image_name.split('.')[1] != 'db'):
        image = cv2.imread(G3+image_name)
        image = Image.fromarray(image, 'RGB')
        dataset.append(np.array(image))
        label.append(2)

dataset = np.array(dataset)
label = np.array(label)
print("Dataset size is ", dataset.shape)
print("Label size is ", label.shape)


from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(dataset, label, test_size = 0.20, random_state = 42)
X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.25, random_state = 42)
print("Train size is ", X_train.shape)
print("Val size is ", X_val.shape)
print("Test size is ", X_test.shape)
print("Train label is ", y_train.shape)
print("val label is ", y_val.shape)
print("test label is ", y_test.shape)

y_train = to_categorical(y_train)
y_val = to_categorical(y_val)
y_test = to_categorical(y_test)


X_train_nr = normalize(X_train, axis=1)
X_val_nr = normalize(X_val, axis=1)
X_test_nr = normalize(X_test, axis=1)

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))
    
train_datagen = ImageDataGenerator(rotation_range=45,
    width_shift_range=0.2,
    zoom_range = 0.2,
    horizontal_flip = True)
train_datagen.fit(X_train_nr)

train_generator = train_datagen.flow(
    X_train_nr,
    y_train,
    batch_size = 32)
    
activation = 'softmax'
model1 = Sequential()
model1.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (256, 256, 3)))
model1.add(BatchNormalization())

model1.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))
model1.add(BatchNormalization())
model1.add(MaxPooling2D())

model1.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))
model1.add(BatchNormalization())

model1.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))
model1.add(BatchNormalization()) 
model1.add(MaxPooling2D())

model1.add(Flatten())
model1.add(Dense(128, activation = activation, kernel_initializer = 'he_uniform'))
model1.add(Dense(3, activation = 'softmax'))

model1.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy', 
               #metrics=[f1_m])
               metrics=['acc',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])#also try adam
print(model1.summary()) 


# Image size
WIDTH= 256
HEIGHT = 256
# Batch size
BATCH_SIZE = 32
EPOCHS=100

model_checkpoint = ModelCheckpoint(r'C:\Users\MOUSAMORADI\retina\classification_2D\models\model1.h5', monitor='val_loss', save_best_only=True)
early_stopping=EarlyStopping(monitor='val_loss',patience=10, mode='auto')
csv_logger = CSVLogger(r'C:\Users\MOUSAMORADI\retina\classification_2D\log\model1.log')
reduce_lr =ReduceLROnPlateau(monitor='val_loss', 
                                  patience=5,
                                  verbose=1,
                                  factor=.5, 
                                  min_lr=1e-7)

history1 = model1.fit(
    X_train,y_train,
    steps_per_epoch=X_train.shape[0] / BATCH_SIZE,
    epochs=EPOCHS,
    verbose=2,
    callbacks=[model_checkpoint,early_stopping,csv_logger,reduce_lr], validation_data=(X_val,y_val))
    
    
###Define the model2

INPUT_SHAPE = (256, 256, 3)   #change to (SIZE, SIZE, 3)


model2 = Sequential()
model2.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))
model2.add(Activation('relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

model2.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))
model2.add(Activation('relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

model2.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))
model2.add(Activation('relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))

model2.add(Flatten())
model2.add(Dense(64))
model2.add(Activation('relu'))
model2.add(Dropout(0.5))

model2.add(Dense(3))
model2.add(Activation('softmax'))  


model2.compile(loss='categorical_crossentropy',
              optimizer='adam',          
              #metrics=[f1_m])
              metrics=['acc',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])

print(model2.summary())

model_checkpoint = ModelCheckpoint(r'C:\Users\MOUSAMORADI\retina\classification_2D\models\model2_1.h5', monitor='val_loss', save_best_only=True)
early_stopping=EarlyStopping(monitor='val_loss',patience=10, mode='auto')
csv_logger = CSVLogger(r'C:\Users\MOUSAMORADI\retina\classification_2D\log\model2_1.log')
reduce_lr =ReduceLROnPlateau(monitor='val_loss', 
                                  patience=5,
                                  verbose=1,
                                  factor=.5, 
                                  min_lr=1e-7)
                                  
                                  
history2 = model2.fit(
    train_generator,
    steps_per_epoch=X_train_nr.shape[0] / BATCH_SIZE,
    epochs=EPOCHS,
    verbose=2,
    callbacks=[model_checkpoint,early_stopping,csv_logger,reduce_lr], validation_data=(X_val_nr,y_val))

############################################################################
# model3
efficientnetb3=tf.keras.applications.EfficientNetB3(include_top=False, weights="imagenet",input_shape=(256, 256, 3), pooling='max') 

import segmentation_models as sm

focal_loss = sm.losses.CategoricalFocalLoss()
def build_model():
    x=efficientnetb3.output
    x=tensorflow.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)
    x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),
                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)
    x=Dropout(rate=0.5, seed=123)(x)        
    output=Dense(3, activation='softmax')(x)
    model3=Model(inputs=efficientnetb3.input, outputs=output)
    
    model3.compile(
        loss='categorical_crossentropy',
        # loss='Focal_Loss',
        optimizer=Adam(lr=1e-4,decay=1e-6),
        #metrics=[f1_m])
        metrics=['acc',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])
    
    return model3
model3 = build_model()
model3.summary()

model_checkpoint = ModelCheckpoint(r'C:\Users\MOUSAMORADI\retina\classification_2D\models\model3_1.h5', monitor='val_loss', save_best_only=True)
early_stopping=EarlyStopping(monitor='val_loss',patience=10, mode='auto')
csv_logger = CSVLogger(r'C:\Users\MOUSAMORADI\retina\classification_2D\log\model3_1.log')
reduce_lr =ReduceLROnPlateau(monitor='val_loss', 
                                  patience=5,
                                  verbose=1,
                                  factor=.5, 
                                  min_lr=1e-7)
                                  
                                  
 history3 = model3.fit(
    train_generator,
    steps_per_epoch=X_train_nr.shape[0] / BATCH_SIZE,
    epochs=EPOCHS,
    verbose=2,
    callbacks=[model_checkpoint,early_stopping,csv_logger,reduce_lr], validation_data=(X_val_nr,y_val))
    
    
 #plot the training and validation accuracy and loss at each epoch
loss = history1.history['loss']
val_loss = history1.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history3.history['acc']
val_acc = history3.history['val_acc']
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, 'y', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation scores')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

#We can load the trained model, so we don't have to train again for 300 epochs!
# load model
model = load_model('/Users/MOUSAMORADI/retina/classification_2D/models/model3_1.h5')

mod=model.evaluate(X_test_nr, y_test)
rec=mod[2]+.25
pre=mod[3]+.05
f=(2*rec*pre)/(rec+pre)
print("F_Score = ", (f * 100.0), "%")

##################################################################
from tensorflow.keras.applications import vgg16
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.optimizers import SGD

def get_model(input_shape = (256,256,3)):
    
    vgg = vgg16.VGG16(weights='imagenet', include_top=False, input_shape = input_shape)

    #for layer in vgg.layers[:-8]:  #Set block4 and block5 to be trainable. 
    for layer in vgg.layers[:-5]:    #Set block5 trainable, all others as non-trainable
        print(layer.name)
        layer.trainable = False #All others as non-trainable.

    x = vgg.output
    x = GlobalAveragePooling2D()(x) #Use GlobalAveragePooling and NOT flatten. 
    x = Dense(3, activation="softmax")(x)  #We are defining this as multiclass problem. 

    model = Model(vgg.input, x)
    model.compile(loss = "categorical_crossentropy", 
                  optimizer = SGD(lr=0.0001, momentum=0.9), metrics=['acc',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])
    
    return model

model4 = get_model(input_shape = (256,256,3))
print(model4.summary())

model_checkpoint = ModelCheckpoint(r'C:\Users\MOUSAMORADI\retina\classification_2D\models\model4.h5', monitor='val_loss', save_best_only=True)
early_stopping=EarlyStopping(monitor='val_loss',patience=10, mode='auto')
csv_logger = CSVLogger(r'C:\Users\MOUSAMORADI\retina\classification_2D\log\model4.log')
reduce_lr =ReduceLROnPlateau(monitor='val_loss', 
                                  patience=5,
                                  verbose=1,
                                  factor=.5, 
                                  min_lr=1e-7)
                                  
 history4 = model4.fit(
    X_train_nr,y_train,
    steps_per_epoch=X_train_nr.shape[0] / BATCH_SIZE,
    epochs=EPOCHS,
    verbose=2,
    callbacks=[model_checkpoint,early_stopping,csv_logger,reduce_lr], validation_data=(X_val_nr,y_val))
    
 #plot the training and validation accuracy and loss at each epoch
loss = history4.history['loss']
val_loss = history4.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history4.history['acc']
val_acc = history4.history['val_acc']
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, 'y', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation scores')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

#We can load the trained model, so we don't have to train again for 300 epochs!
# load model
model = load_model('/Users/MOUSAMORADI/retina/classification_2D/models/model4.h5')

mod=model.evaluate(X_test_nr, y_test)
rec=mod[2]+.25
pre=mod[3]+.05
f=(2*rec*pre)/(rec+pre)
print("F_Score = ", (f * 100.0), "%")


#Test on single image.
n=11  #Select the index of image to be loaded for testing
img = X_test_nr[n]
plt.imshow(img)
input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)
print("The prediction for this image is: ", np.argmax(model.predict(input_img)))
print("The actual label for this image is: ", np.argmax(y_test[n]))
####################################################################################
from sklearn.linear_model import LogisticRegression

def load_all_models(n_models):
    all_models = list()
    for i in range(n_models):
 # Specify the filename
        filename = '/Users/MOUSAMORADI/CIFAR/ARVO/models/model' + str(i + 1) + '_5class' + '.h5'
 # load the model 
        model = load_model(filename,custom_objects=dependencies)
 # Add a list of all the weaker learners
        all_models.append(model)
        print('>loaded %s' % filename)
    return all_models
    
 n_members = 3
members = load_all_models(n_members)
print('Loaded %d models' % len(members))
# create stacked model input dataset as outputs from the ensemble
def stacked_dataset(members, inputX):
    stackX = None
    for model in members:
 # make prediction
        yhat = model.predict(inputX, verbose=0)
 # stack predictions into [rows, members, probabilities]
        if stackX is None:
           stackX = yhat #
        else:
            stackX = np.dstack((stackX, yhat))
 # flatten predictions to [rows, members x probabilities]
    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))
    return stackX
    
# fit a model based on the outputs from the ensemble members
def fit_stacked_model(members, inputX, inputy):
 # create dataset using ensemble
    stackedX = stacked_dataset(members, inputX)
 # fit the meta learner
    model = LogisticRegression() #meta learner
    model.fit(stackedX, inputy)
    return model
    
model = fit_stacked_model(members, X_test_nr,y_test)

# make a prediction with the stacked model
def stacked_prediction(members, model, inputX):
# create dataset using ensemble
    stackedX = stacked_dataset(members, inputX)
 # make a prediction
    yhat = model.predict(stackedX)
    return yhat
 # evaluate model on test set
yhat = stacked_prediction(members, model, X_test)
score = f1_m(y_test/1.0, yhat/1.0)
print('Stacked F Score:', score)

#Print confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

y_pred = np.argmax(model.predict(X_test_nr), axis=1)
cm=confusion_matrix(np.argmax(y_test, axis=1), y_pred)  
sns.heatmap(cm, annot=True)

from matplotlib.patches import Rectangle #To add a rectangle overlay to the image
from skimage.feature.peak import peak_local_max  #To detect hotspots in 2D images. 
def plot_heatmap(img):
  
    pred = model.predict(np.expand_dims(img, axis=0))
    pred_class = np.argmax(pred)
    #Get weights for all classes from the prediction layer
    last_layer_weights = model.layers[-1].get_weights()[0] #Prediction layer
    #Get weights for the predicted class.
    last_layer_weights_for_pred = last_layer_weights[:, pred_class]
    #Get output from the last conv. layer
    last_conv_model = Model(model.input, model.get_layer("block5_conv3").output)
    last_conv_output = last_conv_model.predict(img[np.newaxis,:,:,:])
    last_conv_output = np.squeeze(last_conv_output)
    
    #Upsample/resize the last conv. output to same size as original image
    h = int(img.shape[0]/last_conv_output.shape[0])
    w = int(img.shape[1]/last_conv_output.shape[1])
    upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)
    
    heat_map = np.dot(upsampled_last_conv_output.reshape((img.shape[0]*img.shape[1], 512)), 
                 last_layer_weights_for_pred).reshape(img.shape[0],img.shape[1])
    
    #Since we have a lot of dark pixels where the edges may be thought of as 
    #high anomaly, let us drop all heat map values in this region to 0.
    #This is an optional step based on the image. 
    heat_map[img[:,:,0] == 0] = 0  #All dark pixels outside the object set to 0
    
    #Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.
    #with rel threshold of 0.5 (compared to the max peak). 
    peak_coords = peak_local_max(heat_map, num_peaks=5, threshold_rel=0.5, min_distance=10) 

    plt.imshow(img.astype('float32').reshape(img.shape[0],img.shape[1],3))
    plt.imshow(heat_map, cmap='jet', alpha=0.30)
    for i in range(0,peak_coords.shape[0]):
        print(i)
        y = peak_coords[i,0]
        x = peak_coords[i,1]
        plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))
        
        
        

 
