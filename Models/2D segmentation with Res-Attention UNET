from tensorflow.keras import models, layers, regularizers
from tensorflow.keras import backend as K
import random
import os
import numpy as np
from matplotlib import pyplot as plt
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
from datetime import datetime 
import cv2
from glob import glob
from PIL import Image
from tensorflow.keras import backend, optimizers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,CSVLogger
from patchify import patchify
from PIL import Image
import segmentation_models as sm
from tensorflow.keras.metrics import MeanIoU

### Split useful images to train/validation and test set
import splitfolders  # or import split_folders

input_folder = 'B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G3/images_with _useful_info/'
output_folder = 'B:/Macular cube data/Mousa_python/CLAHE/dataset/G3/'

# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.
splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .15,.10), group_prefix=None) # default values

train_img_dir = "B:/Macular cube data/Mousa_python/CLAHE/dataset/data_for_keras_aug/G3/train_images/train/"
train_mask_dir = "B:/Macular cube data/Mousa_python/CLAHE/dataset/data_for_keras_aug/G3/train_masks/train/"
val_img_dir = "B:/Macular cube data/Mousa_python/CLAHE/dataset/data_for_keras_aug/G3/val_images/val/"
val_mask_dir = "B:/Macular cube data/Mousa_python/CLAHE/dataset/data_for_keras_aug/G3/val_masks/val/"
test_img_dir = "B:/Macular cube data/Mousa_python/CLAHE/dataset/data_for_keras_aug/G3/test_images/test/"
test_mask_dir = "B:/Macular cube data/Mousa_python/CLAHE/dataset/data_for_keras_aug/G3/test_masks/test/"

### images to list and append them as an array

img_list_tr = os.listdir(train_img_dir)
def last_8chars(x):
    return(x[-8:])

img_list_tr=sorted(img_list_tr, key = last_4chars) 

msk_list_tr = os.listdir(train_mask_dir)
def last_8chars(x):
    return(x[-8:])

msk_list_tr=sorted(msk_list_tr, key = last_4chars) 

img_list_val = os.listdir(val_img_dir)
msk_list_val = os.listdir(val_mask_dir)
img_list_tst = os.listdir(test_img_dir)
msk_list_tst = os.listdir(test_mask_dir)

num_images = len(os.listdir(train_img_dir))


img_num = random.randint(0, num_images-1)

img_for_plot = cv2.imread(train_img_dir+img_list_tr[img_num], 1)
img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)

mask_for_plot =cv2.imread(train_mask_dir+msk_list_tr[img_num], 1)

plt.figure(figsize=(12, 8))
plt.subplot(121)
plt.imshow(img_for_plot)
plt.title('Image')
plt.subplot(122)
plt.imshow(mask_for_plot)
plt.title('Mask')
plt.show()

image_dataset_tr = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  

images = os.listdir(train_img_dir)
def last_40chars(x):
    return(x[:40])

images=sorted(images, key = last_4chars) 

for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object
     if image_name.endswith(".jpg"):   #Only read jpg images...
        #print(train_img_dir+image_name)
        image = cv2.imread(train_img_dir+image_name, 1)
        
        # image = Image.fromarray(image)
        image = np.array(image)             
                        
        #Use minmaxscaler instead of just dividing by 255. 
        image = scaler.fit_transform(image.reshape(-1, image.shape[-1])).reshape(image.shape)
                
        image_dataset_tr.append(image)
        
mask_dataset_tr = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  

masks = os.listdir(train_mask_dir)
def last_4chars(x):
    return(x[:40])

masks=sorted(masks, key = last_4chars) 
for i, mask_name in enumerate(masks):    #Remember enumerate method adds a counter and returns the enumerate object
     if mask_name.endswith(".png"):   #Only read jpg images...
        #print(train_img_dir+image_name)
        mask = cv2.imread(train_mask_dir+mask_name, 1)
        #mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)
        # image = Image.fromarray(image)
        mask = np.array(mask)             
        mask_dataset_tr.append(mask)
        
       
image_dataset_test = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  

images = os.listdir(test_img_dir)
def last_40chars(x):
    return(x[:40])

images=sorted(images, key = last_4chars) 
for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object
     if image_name.endswith(".jpg"):   #Only read jpg images...
        #print(train_img_dir+image_name)
        image = cv2.imread(test_img_dir+image_name, 1)
        
        # image = Image.fromarray(image)
        image = np.array(image)             
                        
        #Use minmaxscaler instead of just dividing by 255. 
        image = scaler.fit_transform(image.reshape(-1, image.shape[-1])).reshape(image.shape)
                
        image_dataset_test.append(image)
        
mask_dataset_test = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  

masks = os.listdir(test_mask_dir)
def last_4chars(x):
    return(x[:40])

masks=sorted(masks, key = last_4chars)
for i, mask_name in enumerate(masks):    #Remember enumerate method adds a counter and returns the enumerate object
     if mask_name.endswith(".png"):   #Only read jpg images...
        #print(train_img_dir+image_name)
        mask = cv2.imread(test_mask_dir+mask_name, 1)
        #mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)
        # image = Image.fromarray(image)
        mask = np.array(mask)             
        mask_dataset_test.append(mask)
        
image_dataset_tr = np.array(image_dataset_tr)
mask_dataset_tr  =  np.array(mask_dataset_tr)
image_dataset_val = np.array(image_dataset_val)
mask_dataset_val  =  np.array(mask_dataset_val)
image_dataset_test = np.array(image_dataset_test)
mask_dataset_test  =  np.array(mask_dataset_test)


print("Train dataset is ", image_dataset_tr.shape)
print("Val dataset is ", image_dataset_val.shape)
print("Test dataset is ", image_dataset_test.shape)
print("Train label is ", mask_dataset_tr.shape)
print("val label is ", mask_dataset_val.shape)
print("test label is ", mask_dataset_test.shape)

###RGB values for each retinal layers
class_dict_df = pd.read_csv('B:/Macular cube data/Mousa_python/CLAHE/dataset/class_dict.csv', index_col=False, skipinitialspace=True)
class_dict_df

label_names= list(class_dict_df.name)
label_codes = []
r= np.asarray(class_dict_df.r)
g= np.asarray(class_dict_df.g)
b= np.asarray(class_dict_df.b)

for i in range(len(class_dict_df)):
    label_codes.append(tuple([r[i], g[i], b[i]]))
    
label_codes, label_names
code2id = {v:k for k,v in enumerate(label_codes)}
id2code = {k:v for k,v in enumerate(label_codes)}

name2id = {v:k for k,v in enumerate(label_names)}
id2name = {k:v for k,v in enumerate(label_names)}

def rgb_to_onehot(rgb_image, colormap = id2code):
    '''Function to one hot encode RGB mask labels
        Inputs: 
            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)
            colormap - dictionary of color to label id
        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)
    '''
    num_classes = len(colormap)
    shape = rgb_image.shape[:2]+(num_classes,)
    encoded_image = np.zeros( shape, dtype=np.int8 )
    for i, cls in enumerate(colormap):
        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])
    return encoded_image


def onehot_to_rgb(onehot, colormap = id2code):
    '''Function to decode encoded mask labels
        Inputs: 
            onehot - one hot encoded image matrix (height x width x num_classes)
            colormap - dictionary of color to label id
        Output: Decoded RGB image (height x width x 3) 
    '''
    single_layer = np.argmax(onehot, axis=-1)
    output = np.zeros( onehot.shape[:2]+(3,) )
    for k in colormap.keys():
        output[single_layer==k] = colormap[k]
    return np.uint8(output)
    
labels_tr = []
for i in range(mask_dataset_tr.shape[0]):
    label = rgb_to_onehot(mask_dataset_tr[i], id2code)
    labels_tr.append(label)
labels_val = []
for i in range(mask_dataset_val.shape[0]):
    label = rgb_to_onehot(mask_dataset_val[i],id2code)
    labels_val.append(label) 
labels_test = []
for i in range(mask_dataset_test.shape[0]):
    label = rgb_to_onehot(mask_dataset_test[i],id2code)
    labels_test.append(label) 
labels_tr = np.expand_dims(labels_tr, axis=-1)
labels_val = np.expand_dims(labels_val, axis=-1)
labels_test = np.expand_dims(labels_test, axis=-1)

labels_tr=labels_tr[:,:,:,:,0]
labels_val=labels_val[:,:,:,:,0]
labels_test=labels_test[:,:,:,:,0]
X_train=image_dataset_tr
y_train=labels_tr
X_val=image_dataset_val
y_val=labels_val
X_test=image_dataset_test
y_test=labels_test
print("Train size is ", X_train.shape)
print("Val size is ", X_val.shape)
print("Test size is ", X_test.shape)
print("Train label is ", y_train.shape)
print("val label is ", y_val.shape)
print("test label is ", y_test.shape)

y_train=tf.cast(y_train, tf.float32)
y_val=tf.cast(y_val, tf.float32)
y_test=tf.cast(y_test, tf.float32)



smooth=100

def dice_coef(y_true, y_pred):
    y_truef=K.flatten(y_true)
    y_predf=K.flatten(y_pred)
    And=K.sum(y_truef* y_predf)
    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))

def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

def iou(y_true, y_pred):
    intersection = K.sum(y_true * y_pred)
    sum_ = K.sum(y_true + y_pred)
    jac = (intersection + smooth) / (sum_ - intersection + smooth)
    return jac

def jac_distance(y_true, y_pred):
    y_truef=K.flatten(y_true)
    y_predf=K.flatten(y_pred)

    return - iou(y_true, y_pred)
    
IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH  = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]
num_labels = 10  
input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)
#Set Parameters
EPOCHS = 100
BATCH_SIZE = 32
learning_rate = 1e-4


weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,0.1, 0.1, 0.1]
dice_loss = sm.losses.DiceLoss(class_weights=weights) 
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)  #

##########################################
def conv_block(x, filter_size, size, dropout, batch_norm=False):
    
    conv = layers.Conv2D(size, (filter_size, filter_size), padding="same")(x)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation("relu")(conv)

    conv = layers.Conv2D(size, (filter_size, filter_size), padding="same")(conv)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation("relu")(conv)
    
    if dropout > 0:
        conv = layers.Dropout(dropout)(conv)

    return conv


def repeat_elem(tensor, rep):
    # lambda function to repeat Repeats the elements of a tensor along an axis
    #by a factor of rep.
    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape 
    #(None, 256,256,6), if specified axis=3 and rep=2.

     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),
                          arguments={'repnum': rep})(tensor)


def res_conv_block(x, filter_size, size, dropout, batch_norm=False):
    

    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    conv = layers.Activation('relu')(conv)
    
    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=3)(conv)
    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut
    if dropout > 0:
        conv = layers.Dropout(dropout)(conv)

    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)
    if batch_norm is True:
        shortcut = layers.BatchNormalization(axis=3)(shortcut)

    res_path = layers.add([shortcut, conv])
    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)
    return res_path

def gating_signal(input, out_size, batch_norm=False):
   
    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)
    if batch_norm:
        x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    return x

def attention_block(x, gating, inter_shape):
    shape_x = K.int_shape(x)
    shape_g = K.int_shape(gating)

# Getting the x signal to the same shape as the gating signal
    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16
    shape_theta_x = K.int_shape(theta_x)

# Getting the gating signal to the same number of filters as the inter_shape
    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)
    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),
                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),
                                 padding='same')(phi_g)  # 16

    concat_xg = layers.add([upsample_g, theta_x])
    act_xg = layers.Activation('relu')(concat_xg)
    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)
    sigmoid_xg = layers.Activation('softmax')(psi)
    shape_sigmoid = K.int_shape(sigmoid_xg)
    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32

    upsample_psi = repeat_elem(upsample_psi, shape_x[3])

    y = layers.multiply([upsample_psi, x])

    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)
    result_bn = layers.BatchNormalization()(result)
    return result_bn
    
def Attention_ResUNet(input_shape, NUM_CLASSES=10, dropout_rate=0.0, batch_norm=True):
    
    # network structure
    FILTER_NUM = 64 # number of basic filters for the first layer
    FILTER_SIZE = 3 # size of the convolutional filter
    UP_SAMP_SIZE = 2 # size of upsampling filters
    # input data
    # dimension of the image depth
    inputs = layers.Input(input_shape, dtype=tf.float32)
    axis = 3

    # Downsampling layers
    # DownRes 1, double residual convolution + pooling
    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)
    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)
    # DownRes 2
    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)
    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)
    # DownRes 3
    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)
    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)
    # DownRes 4
    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)
    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)
    # DownRes 5, convolution only
    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)

    # Upsampling layers
    # UpRes 6, attention gated concatenation + upsampling + double residual convolution
    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)
    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)
    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(conv_8)
    up_16 = layers.concatenate([up_16, att_16], axis=axis)
    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 7
    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)
    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)
    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_16)
    up_32 = layers.concatenate([up_32, att_32], axis=axis)
    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 8
    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)
    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)
    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_32)
    up_64 = layers.concatenate([up_64, att_64], axis=axis)
    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)
    # UpRes 9
    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)
    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)
    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format="channels_last")(up_conv_64)
    up_128 = layers.concatenate([up_128, att_128], axis=axis)
    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)

    # 1*1 convolutional layers
    
    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)
    conv_final = layers.BatchNormalization(axis=axis)(conv_final)
    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel

    # Model integration
    model = models.Model(inputs, conv_final, name="AttentionResUNet")
    return model
IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH  = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]
num_labels = 10
input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)
#Set Parameters
EPOCHS = 100
BATCH_SIZE = 16
learning_rate = 1e-4

res_attunet_model = Attention_ResUNet(input_shape)

res_attunet_model.compile(optimizer=Adam(lr = 1e-4), loss=total_loss, 
              metrics=["accuracy", iou, dice_coef, tf.keras.metrics.Recall(),
                                                           tf.keras.metrics.Precision()])
#BinaryFocalLoss(gamma=2)
print(res_attunet_model.summary())


import keract
import pickle
import numpy as np
import pandas as pd
from PIL import Image
import albumentations as A
from IPython.display import SVG
import matplotlib.pyplot as plt
%matplotlib inline
import os, re, sys, random, shutil, cv2

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam, Nadam
from tensorflow.keras import applications, optimizers
from tensorflow.keras.applications import InceptionResNetV2
from tensorflow.keras.applications.resnet50 import preprocess_input

from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.utils import model_to_dot, plot_model
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout

SVG(model_to_dot(res_attunet_model).create(prog='dot', format='svg'))
plot_model(res_attunet_model, to_file='model.png', show_shapes=True, show_layer_names=True, expand_nested=True)


es = EarlyStopping(monitor='val_loss', patience=5, verbose=1)
csv_logger = CSVLogger(r'C:\Users\MOUSAMORADI\retina\log\G3\resattunet1_{}.log'.format(datetime.now().strftime("%Y_%m_%d-%H_%M")))
callbacks = [ModelCheckpoint(r'C:\Users\MOUSAMORADI\retina\models\G3\resattunet1.hdf5', verbose=1, save_weights_only=True), csv_logger]

reduce_lr = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.2,patience=7, min_lr=1e-5,verbose=1)


start2 = datetime.now() 
history3 =res_attunet_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, shuffle=False,
              callbacks=callbacks, validation_data=(X_val, y_val))
stop2 = datetime.now()
execution_time_Att_Res_Unet = stop2-start2
print("Res_Attention UNet execution time is: ", execution_time_Att_Res_Unet)



history = history3
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['iou']
val_acc = history.history['val_iou']

plt.plot(epochs, acc, 'y', label='Training IoU')
plt.plot(epochs, val_acc, 'r', label='Validation IoU')
plt.title('Training and validation IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU')
plt.legend()
plt.show()


#IOU
y_pred=model_resnet_backbone.predict(X_test_prepr)
y_pred_argmax=np.argmax(y_pred, axis=3)
y_test_argmax=np.argmax(y_test, axis=3)
#Using built in keras function for IoU
from tensorflow.keras.metrics import MeanIoU
n_classes = 10
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_test_argmax, y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())


results = model_resnet_backbone.evaluate(X_test_prepr, y_test)
print("Test lost: ",results[0])
print("Test IOU: ",results[1])
print("Test Dice Coefficent: ",results[2])


#######################################################################
#Predict on a few images

import random
# test_img_number = random.randint(0, len(X_test))
test_img = X_test[0]
ground_truth=y_test_argmax[0]
#test_img_norm=test_img[:,:,0][:,:,None]
test_img_input=np.expand_dims(test_img, 0)
prediction = (res_attunet_model.predict(test_img_input))
predicted_img=np.argmax(prediction, axis=3)[0,:,:]


plt.figure(figsize=(12, 8))
plt.subplot(231)
plt.title('Testing Image')
plt.imshow(test_img)
plt.subplot(232)
plt.title('Testing Label')
plt.imshow(ground_truth)
plt.subplot(233)
plt.title('Prediction on test image')
plt.imshow(predicted_img)
plt.show()


# Loading unknown test Images
X_data=glob(r'B:\Macular cube data\Mousa_python\noCLAHE\dataset\data_for_keras_aug\G3\test_images\test\*.jpg')
y_data=glob(r'B:\Macular cube data\Mousa_python\noCLAHE\dataset\data_for_keras_aug\G3\test_masks\test\*.png')


def last_8chars(x):
    return(x[-8:])

X_data=sorted(X_data, key = last_8chars) 

def last_8chars(x):
    return(x[-8:])

y_data=sorted(y_data, key = last_8chars) 
df_test = pd.DataFrame(data={"filename": X_data, 'mask' : y_data})

#model = model_resnet_backbone
# Restore the weights

#model=model1
model=res_attunet_model
#model_path = "C:/Users/MOUSAMORADI/retina/models/G2/resnet3.hdf5"
#Load one model at a time for testing.
#model = tf.keras.models.load_model(model_path, compile=False)
model.load_weights('./models/G2/resattunet1.hdf5')


# import random
# test_img_number = random.randint(0, X_test.shape[0]-1)
# test_img = X_test[test_img_number]
# ground_truth=y_test[test_img_number]
index=np.random.randint(1,len(df_test.index))
img1 = cv2.imread(df_test['filename'].iloc[24])
plt.figure(figsize=(12,12))
plt.subplot(1,4,1)
plt.imshow(np.squeeze(img1))
plt.title('Original Image')
img = cv2.resize(img1 ,(256, 256))
img = img / 255
img = img[np.newaxis, :, :, :]
pred=model.predict(img)
pred=np.argmax(pred, axis=3)[0,:,:]

# pre=np.squeeze(pred) > .05
mask = cv2.imread(df_test['mask'].iloc[24])
plt.subplot(1,4,2)
plt.imshow(mask)
plt.title('Original Mask')
plt.subplot(1,4,3)
plt.imshow(pred)
plt.title('Prediction')
pre=np.uint8(pred)
pre=cv2.cvtColor(pre,cv2.COLOR_BGR2RGB)
p=np.where(pre>0)
m=np.where(mask>0)
pre[p[0:2]]=[0, 255, 0]
mask[m[0:2]]=[255, 0, 0]
dst1 = cv2.addWeighted(pre,1,mask,1,0)
dst2 = cv2.addWeighted(img1,1,dst1,1,0)
plt.subplot(1,4,4)
plt.imshow(dst2)
plt.title('Overlay')
plt.show()
