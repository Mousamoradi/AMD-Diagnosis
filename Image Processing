# Mousa Moradi_ Ph.D. student in biomedical engineerin, UMASS AMHERST, UMASS MEDICAL SCHOOL WORCESTER
#
# Image Processing and data preparation: Contrast Limited Adaptive Histogram Equalization (CLAHE)+ Canny edge detection and contour detection for retinal layer extraction
# What version of Python?
# For image processing opencv>4.4 is needed. (Tensorflow cpu only)
import sys

import tensorflow.keras
import pandas as pd
import sklearn as sk
import tensorflow as tf

print(f"Tensor Flow Version: {tf.__version__}")
print(f"Keras Version: {tensorflow.keras.__version__}")
print()
print(f"Python {sys.version}")
print(f"Pandas {pd.__version__}")
print(f"Scikit-Learn {sk.__version__}")
print("GPU is", "available" if tf.config.list_physical_devices() \
      else "NOT AVAILABLE")
tf.config.list_physical_devices()

# import library and modules
from PIL import Image
import cv2
import matplotlib.pyplot as plt
#from keras.preprocessing.image import ImageDataGenerator
import glob
import os
import sys
import numpy as np
from tqdm import tqdm
%matplotlib qt5
from shutil import copyfile
from skimage import morphology
from mpl_toolkits.axes_grid1 import make_axes_locatable
from skimage.morphology import label
from PIL import Image,ImageDraw,ImageFont
import pandas as pd 
from datetime import datetime
#from keras import utils as np_utils
from tensorflow.keras import utils as np_utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#%matplotlib qt5
#plt.style.use("dark_background")
# Loading original Images
X_data=glob.glob(r'B:\Macular cube data\allinone_g3\macula\org\org_size\*.tif')
y_data=glob.glob(r'B:\Macular cube data\allinone_g3\macula\groundtruth\*.tif')
def last_8chars(x):    #sort original images based on the last 8 characters
    return(x[-8:])
X_data=sorted(X_data, key = last_8chars) 
def last_8chars(x):     #sort ground truh based on the last 8 characters
    return(x[-8:])
y_data=sorted(y_data, key = last_8chars) 

df = pd.DataFrame()
df['train'] = X_data
df['ground_truth'] = y_data
df.head()
# check whether all the images have it's corresponding ground_truth
len(df['train']) == len(df['ground_truth'])
%%time
import time

df['diag'] = 3
for i in range(len(df)):
  img = df['ground_truth'].iloc[i]
  value = np.max(cv2.imread(img))
  if value > 0: 
    df['diag'].iloc[i] = 1
  else: 
    df['diag'].iloc[i] = 0
df.head()
# We have a total of 14497 images with segmented PCT lumen and 2 images with no segmented PCT lumen.
df['diag'].value_counts()
# Sanity check
# Visualizing 3- see original/ground_truth and segmented area
fig=plt.figure(figsize=(10,10))

#plotting the image
fig.add_subplot(1,3,1)
img = cv2.imread(df['train'].iloc[700])
plt.imshow(img)

#plotting the ground truth
fig.add_subplot(1,3,2)
msk = cv2.imread(df['ground_truth'].iloc[700])
msk = cv2.cvtColor(msk,cv2.COLOR_BGR2RGB)

plt.imshow(msk)

#plotting the mask overlayed on the image
fig.add_subplot(1,3,3)
#identify the edges using the CannyEdgeDetector
edged = cv2.Canny(msk, 10, 250)
#find the contours on the the image(edge detected)
(cnts, _)= cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
#draw the contours
for cnt in cnts:
    cv2.drawContours(img,[cnt],0,(255,0,0),2)
plt.imshow(img)
# Image Enhancement using CLAHE
#load an image from the dataset
def enh_img():
    for i in tqdm(range(len(df))):
        imgfile_org=df['train'].iloc[i]
        imgfile_gt=df['ground_truth'].iloc[i]
        name_org = os.path.basename(imgfile_org)
        name_gt = os.path.basename(imgfile_gt)
        
        img = cv2.imread(imgfile_org)
        mask = cv2.imread(imgfile_gt)
        
        #set the clip value and the gridsize changing these values will give different output
        clahe = cv2.createCLAHE(clipLimit=2, \
                                tileGridSize=(16,16))
        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        equ=clahe.apply(grayimg)
        equ = cv2.cvtColor(equ,cv2.COLOR_BGR2RGB)
        imgc = grayimg.copy()

        #Now we can now crop the image.
        #to crop the image we'll first find the edges in the image.
        edged = cv2.Canny(grayimg, 50, 180)

        #Once we have the edges now we'll perform dilate operation to remove any small regions of noises
        dilate = cv2.dilate(edged, None, iterations=15)

        #Now we can find the contours in the image
        (cnts, thres) = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        #for c in cnts:
             #peri = cv2.arcLength(c, True)
             #eps = 0.01 * peri
             #approx = cv2.approxPolyDP(c, eps, True)
             #cv2.drawContours(imgc, [approx], -1, (0, 255, 0), 2)

#Now we'll get the extreme points in the contours and crop the image
#https://www.pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/
        c = max(cnts, key=cv2.contourArea)

        extLeft = tuple(c[c[:, :, 0].argmin()][0])
        extRight = tuple(c[c[:, :, 0].argmax()][0])
        extTop = tuple(c[c[:, :, 1].argmin()][0])
        extBot = tuple(c[c[:, :, 1].argmax()][0])
        new_image = img[extTop[1]:extBot[1], extLeft[0]:extRight[0]]
        mask = mask[extTop[1]:extBot[1], extLeft[0]:extRight[0]]

        cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/dataset/contour/G3/org', name_org + str(i) + '.jpg'), new_image)
        cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/dataset/contour/G3/gt', name_gt + str(i) + '.png'), mask)
enh_img()

# # Splitting into 4 sets

def split_img():
    j=0
    for i in tqdm(range(len(df))):
        imgfile_org=df['train'].iloc[i]
        imgfile_gt=df['ground_truth'].iloc[i]
        name_org = os.path.basename(imgfile_org)
        name_gt = os.path.basename(imgfile_gt)
        
        img = cv2.imread(imgfile_org)
        mask = cv2.imread(imgfile_gt)
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        height,width= gray.shape
        CROP_W_SIZE=4
        for iw in range(CROP_W_SIZE ):
            x = width // CROP_W_SIZE*iw
            w = (width //CROP_W_SIZE )
            t1 = gray[:, x:x+256]
            m1= mask[:, x:x+256]
            cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/split/org', name_org + str(iw) + '.jpg'), t1)
            cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/split/gt' ,name_gt + str(iw) + '.jpg'), m1)
            j=j+1
split_img()
