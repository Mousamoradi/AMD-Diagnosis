# Mousa Moradi_ Ph.D. student in biomedical engineerin, UMASS AMHERST, UMASS MEDICAL SCHOOL WORCESTER
# Department of Ophthalmology and Visual Sciences, UMASS CHAN MEDICAL SCHOOL, WORCESTER, MA, USA
# For redistribution and sharing: mousamoradi@umass.edu
#
# Image Processing and data preparation: Contrast Limited Adaptive Histogram Equalization (CLAHE)+ Canny edge detection and contour detection for retinal layer extraction
# What version of Python?
# For image processing opencv>4.4 is needed. (Tensorflow cpu only)
import sys

import tensorflow.keras
import pandas as pd
import sklearn as sk
import tensorflow as tf

print(f"Tensor Flow Version: {tf.__version__}")
print(f"Keras Version: {tensorflow.keras.__version__}")
print()
print(f"Python {sys.version}")
print(f"Pandas {pd.__version__}")
print(f"Scikit-Learn {sk.__version__}")
print("GPU is", "available" if tf.config.list_physical_devices() \
      else "NOT AVAILABLE")
tf.config.list_physical_devices()

# import library and modules
from PIL import Image
import cv2
import matplotlib.pyplot as plt
#from keras.preprocessing.image import ImageDataGenerator
import glob
import os
import sys
import numpy as np
from tqdm import tqdm
%matplotlib qt5
from shutil import copyfile
from skimage import morphology
from mpl_toolkits.axes_grid1 import make_axes_locatable
from skimage.morphology import label
from PIL import Image,ImageDraw,ImageFont
import pandas as pd 
from datetime import datetime
#from keras import utils as np_utils
from tensorflow.keras import utils as np_utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#%matplotlib qt5
#plt.style.use("dark_background")
# Loading original Images
X_data=glob.glob(r'B:\Macular cube data\allinone_g3\macula\org\org_size\*.tif')
y_data=glob.glob(r'B:\Macular cube data\allinone_g3\macula\groundtruth\*.tif')
def last_8chars(x):    #sort original images based on the last 8 characters
    return(x[-8:])
X_data=sorted(X_data, key = last_8chars) 
def last_8chars(x):     #sort ground truh based on the last 8 characters
    return(x[-8:])
y_data=sorted(y_data, key = last_8chars) 

df = pd.DataFrame()
df['train'] = X_data
df['ground_truth'] = y_data
df.head()
# check whether all the images have it's corresponding ground_truth
len(df['train']) == len(df['ground_truth'])
%%time
import time

df['diag'] = 3
for i in range(len(df)):
  img = df['ground_truth'].iloc[i]
  value = np.max(cv2.imread(img))
  if value > 0: 
    df['diag'].iloc[i] = 1
  else: 
    df['diag'].iloc[i] = 0
df.head()
# We have a total of 14497 images with segmented PCT lumen and 2 images with no segmented PCT lumen.
df['diag'].value_counts()
# Sanity check
# Visualizing 3- see original/ground_truth and segmented area
fig=plt.figure(figsize=(10,10))

#plotting the image
fig.add_subplot(1,3,1)
img = cv2.imread(df['train'].iloc[700])
plt.imshow(img)

#plotting the ground truth
fig.add_subplot(1,3,2)
msk = cv2.imread(df['ground_truth'].iloc[700])
msk = cv2.cvtColor(msk,cv2.COLOR_BGR2RGB)

plt.imshow(msk)

#plotting the mask overlayed on the image
fig.add_subplot(1,3,3)
#identify the edges using the CannyEdgeDetector
edged = cv2.Canny(msk, 10, 250)
#find the contours on the the image(edge detected)
(cnts, _)= cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
#draw the contours
for cnt in cnts:
    cv2.drawContours(img,[cnt],0,(255,0,0),2)
plt.imshow(img)
# Image Enhancement using CLAHE
#load an image from the dataset
def enh_img():
    for i in tqdm(range(len(df))):
        imgfile_org=df['train'].iloc[i]
        imgfile_gt=df['ground_truth'].iloc[i]
        name_org = os.path.basename(imgfile_org)
        name_gt = os.path.basename(imgfile_gt)
        
        img = cv2.imread(imgfile_org)
        mask = cv2.imread(imgfile_gt)
        
        #set the clip value and the gridsize changing these values will give different output
        clahe = cv2.createCLAHE(clipLimit=2, \
                                tileGridSize=(16,16))
        grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        equ=clahe.apply(grayimg)
        equ = cv2.cvtColor(equ,cv2.COLOR_BGR2RGB)
        imgc = grayimg.copy()

        #Now we can now crop the image.
        #to crop the image we'll first find the edges in the image.
        edged = cv2.Canny(grayimg, 50, 180)

        #Once we have the edges now we'll perform dilate operation to remove any small regions of noises
        dilate = cv2.dilate(edged, None, iterations=15)

        #Now we can find the contours in the image
        (cnts, thres) = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        #for c in cnts:
             #peri = cv2.arcLength(c, True)
             #eps = 0.01 * peri
             #approx = cv2.approxPolyDP(c, eps, True)
             #cv2.drawContours(imgc, [approx], -1, (0, 255, 0), 2)

#Now we'll get the extreme points in the contours and crop the image
#https://www.pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/
        c = max(cnts, key=cv2.contourArea)

        extLeft = tuple(c[c[:, :, 0].argmin()][0])
        extRight = tuple(c[c[:, :, 0].argmax()][0])
        extTop = tuple(c[c[:, :, 1].argmin()][0])
        extBot = tuple(c[c[:, :, 1].argmax()][0])
        new_image = img[extTop[1]:extBot[1], extLeft[0]:extRight[0]]
        mask = mask[extTop[1]:extBot[1], extLeft[0]:extRight[0]]

        cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/dataset/contour/G3/org', name_org + str(i) + '.jpg'), new_image)
        cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/dataset/contour/G3/gt', name_gt + str(i) + '.png'), mask)
enh_img()

# Loading the enhanced original and mask Images
image_directory='B:/Macular cube data/Mousa_python/CLAHE/dataset/contour/G3/org/'
mask_directory='B:/Macular cube data/Mousa_python/CLAHE/dataset/contour/G3/gt/'
# Split each image and ground truth to 66 patches
patch_size = 256

image_dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  

images = os.listdir(image_directory)
for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object
     if image_name.endswith(".jpg"):   #Only read jpg images...
        print(image_directory+image_name)
        image = cv2.imread(image_directory+image_name)
        SIZE_X = (image.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size
        SIZE_Y = (image.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size
            
        image = Image.fromarray(image)
        image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner
        image = np.array(image)             

#Extract patches from each image
        #print("Now patchifying image:", image_directory+image_name)
        patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap
        for i in range(patches_img.shape[0]):
            for j in range(patches_img.shape[1]):
                        
                single_patch_img = patches_img[i,j,:,:]
                #Use minmaxscaler instead of just dividing by 255. 
                # single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)
                        
                #single_patch_img = (single_patch_img.astype('float32')) / 255. 
                single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.   
                cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G3/images', 
                                         image_name + "_patch_" + str(i) + str(j) + ".jpg"), single_patch_img)
                # image_dataset.append(single_patch_img)

patch_size = 256

mask_dataset = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.

masks = os.listdir(mask_directory)
for i, mask_name in enumerate(masks):    #Remember enumerate method adds a counter and returns the enumerate object
     if mask_name.endswith(".png"):   #Only read jpg images...
        #print(image_directory+image_name)
        mask = cv2.imread(mask_directory+mask_name,1)
        mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)
        SIZE_X = (mask.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size
        SIZE_Y = (mask.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size
            
        mask = Image.fromarray(mask)
        mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner
        mask = np.array(mask)             

#Extract patches from each image
        print("Now patchifying image:", mask_directory+mask_name)
        patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap
        
        for i in range(patches_mask.shape[0]):
            for j in range(patches_mask.shape[1]):
                        
                single_patch_mask = patches_mask[i,j,:,:]
                single_patch_mask = single_patch_mask[0] 
                cv2.imwrite(os.path.join('B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G3/masks', 
                                         mask_name + "_patch_" + str(i) + str(j) + ".png"), single_patch_mask)
                # mask_dataset.append(single_patch_mask)
# Loading patches
patches_image='B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G3/images/'
patches_mask='B:/Macular cube data/Mousa_python/CLAHE/dataset/256_patches/G3/masks/'     

#Now, let us copy images and masks with real information to a new folder.
# real information = if mask has decent amount of labels other than 0. 

useless=0  #Useless image counter
for img in range(len(img_list)):   #Using t1_list as all lists are of same size
    img_name=img_list[img]
    mask_name = msk_list[img]
    print("Now preparing image and masks number: ", img)
      
    temp_image=cv2.imread(patches_image+img_list[img], 1)
   
    temp_mask=cv2.imread(patches_mask+msk_list[img], 1)
    #temp_mask=temp_mask.astype(np.uint8)
    
    val, counts = np.unique(temp_mask, return_counts=True)
    

    if (1 - (counts[0]/counts.sum())) > 0.05:  #At least 5% useful area with labels that are not 0
        print("Save Me")
        cv2.imwrite('B:/Macular cube data/Mousa_python/noCLAHE/dataset/256_patches/G3/images_with _useful_info/images/'+img_name, temp_image)
        cv2.imwrite('B:/Macular cube data/Mousa_python/noCLAHE/dataset/256_patches/G3/images_with _useful_info/masks/'+mask_name, temp_mask)
        
    else:
        print("I am useless")  
        useless +=1

print("Total useful images are: ", len(img_list)-useless)  #20,075
print("Total useless images are: ", useless) #21,571





